{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T05:50:08.128519Z",
     "iopub.status.busy": "2025-01-06T05:50:08.128332Z",
     "iopub.status.idle": "2025-01-06T05:50:17.636623Z",
     "shell.execute_reply": "2025-01-06T05:50:17.635474Z",
     "shell.execute_reply.started": "2025-01-06T05:50:08.128500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "!kaggle datasets download paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T05:50:17.637908Z",
     "iopub.status.busy": "2025-01-06T05:50:17.637647Z",
     "iopub.status.idle": "2025-01-06T05:50:35.315376Z",
     "shell.execute_reply": "2025-01-06T05:50:35.314407Z",
     "shell.execute_reply.started": "2025-01-06T05:50:17.637888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the path to the zip file\n",
    "zip_file_path = '/kaggle/working/chest-xray-pneumonia.zip'\n",
    "extract_to_path = '.'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(extract_to_path, exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)\n",
    "\n",
    "print(f\"Files extracted to {extract_to_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T05:50:35.316596Z",
     "iopub.status.busy": "2025-01-06T05:50:35.316279Z",
     "iopub.status.idle": "2025-01-06T05:50:40.592170Z",
     "shell.execute_reply": "2025-01-06T05:50:40.591429Z",
     "shell.execute_reply.started": "2025-01-06T05:50:35.316564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T05:50:40.593306Z",
     "iopub.status.busy": "2025-01-06T05:50:40.592948Z",
     "iopub.status.idle": "2025-01-06T05:50:40.603265Z",
     "shell.execute_reply": "2025-01-06T05:50:40.602601Z",
     "shell.execute_reply.started": "2025-01-06T05:50:40.593284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Directory paths for the dataset\n",
    "train_data_dir = '/kaggle/working/chest_xray/train'\n",
    "test_data_dir = '/kaggle/working/chest_xray/test'\n",
    "val_data_dir = '/kaggle/working/chest_xray/val'\n",
    "\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Preprocessing: Resize, Normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.transforms.Normalize(\n",
    "                    mean=[-m / s for m, s in zip(imagenet_mean, imagenet_std)],\n",
    "                    std=[1 / s for s in imagenet_std]\n",
    "                ) \n",
    "])\n",
    "\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root=val_data_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_data_dir, transform=transform)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T05:50:40.604426Z",
     "iopub.status.busy": "2025-01-06T05:50:40.604057Z",
     "iopub.status.idle": "2025-01-06T05:50:42.722158Z",
     "shell.execute_reply": "2025-01-06T05:50:42.721282Z",
     "shell.execute_reply.started": "2025-01-06T05:50:40.604380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "augmented_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.transforms.Normalize(\n",
    "                    mean=[-m / s for m, s in zip(imagenet_mean, imagenet_std)],\n",
    "                    std=[1 / s for s in imagenet_std]\n",
    "                )  # ImageNet stats\n",
    "])\n",
    "\n",
    "# Apply augmentation only to the training dataset\n",
    "train_augmented_data = datasets.ImageFolder(root=train_data_dir, transform=augmented_transform)\n",
    "train_augmented_loader = DataLoader(train_augmented_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T05:50:42.724907Z",
     "iopub.status.busy": "2025-01-06T05:50:42.724681Z",
     "iopub.status.idle": "2025-01-06T05:50:44.270648Z",
     "shell.execute_reply": "2025-01-06T05:50:44.269786Z",
     "shell.execute_reply.started": "2025-01-06T05:50:42.724888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_augmented_loader))\n",
    "print(f\"Image tensor shape: {images.shape}\")  # e.g., [32, 3, 224, 224]\n",
    "print(f\"Pixel value range: {images.min()} to {images.max()}\")  # Should show 0.0 to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T05:50:44.272291Z",
     "iopub.status.busy": "2025-01-06T05:50:44.271998Z",
     "iopub.status.idle": "2025-01-06T05:50:44.618897Z",
     "shell.execute_reply": "2025-01-06T05:50:44.618095Z",
     "shell.execute_reply.started": "2025-01-06T05:50:44.272267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Freeze the pre-trained layers (except the last layer)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)  # 2 output classes: Normal, Pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T05:50:44.620004Z",
     "iopub.status.busy": "2025-01-06T05:50:44.619749Z",
     "iopub.status.idle": "2025-01-06T05:50:44.629134Z",
     "shell.execute_reply": "2025-01-06T05:50:44.628216Z",
     "shell.execute_reply.started": "2025-01-06T05:50:44.619982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PneumoniaNN(nn.Module):\n",
    "    def __init__(self, input_channels=3, num_classes=2):\n",
    "        super(PneumoniaNN, self).__init__()\n",
    "        # Convolutional Layers with BatchNorm and Dropout\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(100352, 512)  # Adjust input size based on your image dimensions\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T05:50:44.630354Z",
     "iopub.status.busy": "2025-01-06T05:50:44.629997Z",
     "iopub.status.idle": "2025-01-06T05:50:44.655302Z",
     "shell.execute_reply": "2025-01-06T05:50:44.654523Z",
     "shell.execute_reply.started": "2025-01-06T05:50:44.630319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0.001, path='best_model.pth', verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after the last improvement.\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "            path (str): Path to save the best model.\n",
    "            verbose (bool): Whether to print updates about early stopping.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = np.inf\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.path = path\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        \"\"\"Saves the model when validation loss improves.\"\"\"\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        if self.verbose:\n",
    "            print(\"Validation loss decreased. Saving model...\")\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, val_loader, num_epochs, learning_rate, patience=5):\n",
    "    \"\"\"\n",
    "    Trains the model with early stopping.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The CNN model to train.\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        val_loader (DataLoader): DataLoader for validation data.\n",
    "        num_epochs (int): Number of epochs to train for.\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "        patience (int): Patience for early stopping.\n",
    "    \"\"\"\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    # Device configuration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        progress_bar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=True)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "            progress_bar.set_description(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct_preds / total_preds\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_preds += (predicted == labels).sum().item()\n",
    "                total_preds += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct_preds / total_preds\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # Early stopping\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load(early_stopping.path))\n",
    "    print(\"Training complete. Best model restored.\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T05:50:44.656316Z",
     "iopub.status.busy": "2025-01-06T05:50:44.655996Z",
     "iopub.status.idle": "2025-01-06T05:50:44.741463Z",
     "shell.execute_reply": "2025-01-06T05:50:44.740656Z",
     "shell.execute_reply.started": "2025-01-06T05:50:44.656294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Move model to GPU if available\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    device = xm.xla_device()  # Automatically detects TPU if available\n",
    "except ImportError:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T05:50:44.742529Z",
     "iopub.status.busy": "2025-01-06T05:50:44.742238Z",
     "iopub.status.idle": "2025-01-06T06:05:48.591577Z",
     "shell.execute_reply": "2025-01-06T06:05:48.590642Z",
     "shell.execute_reply.started": "2025-01-06T05:50:44.742499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# net = PneumoniaCNN(input_size=(3, 224, 224))\n",
    "\n",
    "\n",
    "best_model = train(model, train_augmented_loader, test_loader, num_epochs=20, learning_rate=1e-3, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T06:05:48.593101Z",
     "iopub.status.busy": "2025-01-06T06:05:48.592766Z",
     "iopub.status.idle": "2025-01-06T06:05:48.596480Z",
     "shell.execute_reply": "2025-01-06T06:05:48.595708Z",
     "shell.execute_reply.started": "2025-01-06T06:05:48.593072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch.save(best_model, 'pre_train.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T06:05:48.597522Z",
     "iopub.status.busy": "2025-01-06T06:05:48.597264Z",
     "iopub.status.idle": "2025-01-06T06:20:07.373086Z",
     "shell.execute_reply": "2025-01-06T06:20:07.372347Z",
     "shell.execute_reply.started": "2025-01-06T06:05:48.597494Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "net = PneumoniaNN()\n",
    "\n",
    "custom_best_model = train(net, train_augmented_loader, test_loader, num_epochs=10, learning_rate=1e-3, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T06:20:07.374156Z",
     "iopub.status.busy": "2025-01-06T06:20:07.373890Z",
     "iopub.status.idle": "2025-01-06T06:20:07.377379Z",
     "shell.execute_reply": "2025-01-06T06:20:07.376616Z",
     "shell.execute_reply.started": "2025-01-06T06:20:07.374134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch.save(custom_best_model, 'max.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T06:30:24.737553Z",
     "iopub.status.busy": "2025-01-06T06:30:24.737258Z",
     "iopub.status.idle": "2025-01-06T06:30:25.720448Z",
     "shell.execute_reply": "2025-01-06T06:30:25.719599Z",
     "shell.execute_reply.started": "2025-01-06T06:30:24.737531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data for plotting\n",
    "epochs_1 = list(range(1, 8))  # Epochs for the first run\n",
    "train_loss_1 = [0.2871, 0.2097, 0.1941, 0.1905, 0.1923, 0.1620, 0.1631]\n",
    "val_loss_1 = [0.3853, 0.2111, 0.9361, 0.2268, 0.3088, 0.2348, 0.3207]\n",
    "train_acc_1 = [88.17, 91.60, 92.58, 92.18, 92.47, 94.04, 93.19]\n",
    "val_acc_1 = [84.29, 91.35, 64.74, 90.71, 88.94, 90.54, 87.50]\n",
    "\n",
    "epochs_2 = list(range(1, 8))  # Epochs for the second run\n",
    "train_loss_2 = [2.0530, 0.3820, 0.3805, 0.3700, 0.3652, 0.3789, 0.3797]\n",
    "val_loss_2 = [1.2822, 0.5287, 1.3809, 3.0322, 1.2608, 0.6871, 0.5576]\n",
    "train_acc_2 = [76.42, 82.67, 82.07, 83.45, 81.79, 81.63, 81.90]\n",
    "val_acc_2 = [39.10, 75.16, 41.19, 37.50, 38.78, 40.22, 70.35]\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# First Run - Loss\n",
    "axes[0, 0].plot(epochs_1, train_loss_1, label=\"Train Loss\", marker='o')\n",
    "axes[0, 0].plot(epochs_1, val_loss_1, label=\"Validation Loss\", marker='o')\n",
    "axes[0, 0].set_title(\"Pre-train - Loss\")\n",
    "axes[0, 0].set_xlabel(\"Epochs\")\n",
    "axes[0, 0].set_ylabel(\"Loss\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid()\n",
    "\n",
    "# First Run - Accuracy\n",
    "axes[0, 1].plot(epochs_1, train_acc_1, label=\"Train Accuracy\", marker='o')\n",
    "axes[0, 1].plot(epochs_1, val_acc_1, label=\"Validation Accuracy\", marker='o')\n",
    "axes[0, 1].set_title(\"Pre-train - Accuracy\")\n",
    "axes[0, 1].set_xlabel(\"Epochs\")\n",
    "axes[0, 1].set_ylabel(\"Accuracy (%)\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid()\n",
    "\n",
    "# Second Run - Loss\n",
    "axes[1, 0].plot(epochs_2, train_loss_2, label=\"Train Loss\", marker='o')\n",
    "axes[1, 0].plot(epochs_2, val_loss_2, label=\"Validation Loss\", marker='o')\n",
    "axes[1, 0].set_title(\"Custom CNN - Loss\")\n",
    "axes[1, 0].set_xlabel(\"Epochs\")\n",
    "axes[1, 0].set_ylabel(\"Loss\")\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid()\n",
    "\n",
    "# Second Run - Accuracy\n",
    "axes[1, 1].plot(epochs_2, train_acc_2, label=\"Train Accuracy\", marker='o')\n",
    "axes[1, 1].plot(epochs_2, val_acc_2, label=\"Validation Accuracy\", marker='o')\n",
    "axes[1, 1].set_title(\"Second Run - Accuracy\")\n",
    "axes[1, 1].set_xlabel(\"Epochs\")\n",
    "axes[1, 1].set_ylabel(\"Accuracy (%)\")\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T06:25:05.300161Z",
     "iopub.status.busy": "2025-01-06T06:25:05.299838Z",
     "iopub.status.idle": "2025-01-06T06:25:23.412819Z",
     "shell.execute_reply": "2025-01-06T06:25:23.411892Z",
     "shell.execute_reply.started": "2025-01-06T06:25:05.300134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_test_accuracy(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)  # Move model to device\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get predicted class\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Update correct predictions and total samples\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_accuracy = 100 * correct_preds / total_preds\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "# Assuming `test_loader` is your DataLoader for test data and `best_model` is the trained model\n",
    "test_accuracy = evaluate_test_accuracy(best_model, test_loader)\n",
    "test_accuracy = evaluate_test_accuracy(custom_best_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T06:25:37.483484Z",
     "iopub.status.busy": "2025-01-06T06:25:37.483199Z",
     "iopub.status.idle": "2025-01-06T06:25:37.598746Z",
     "shell.execute_reply": "2025-01-06T06:25:37.598055Z",
     "shell.execute_reply.started": "2025-01-06T06:25:37.483463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dir='/kaggle/working/chest_xray/test/NORMAL'\n",
    "from skimage.io import imread\n",
    "from PIL import Image\n",
    "import glob\n",
    "image_list = []\n",
    "for filename in glob.glob(test_dir+'/*.jpeg'):\n",
    "    #im=Image.open(filename)\n",
    "    image_list.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T06:25:57.129831Z",
     "iopub.status.busy": "2025-01-06T06:25:57.129406Z",
     "iopub.status.idle": "2025-01-06T06:25:59.327627Z",
     "shell.execute_reply": "2025-01-06T06:25:59.326408Z",
     "shell.execute_reply.started": "2025-01-06T06:25:57.129805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import math\n",
    "\n",
    "def plot_input(image_list):\n",
    "    num_images = len(image_list)\n",
    "    grid_size = math.ceil(math.sqrt(num_images))  # Determine grid size dynamically\n",
    "    fig, ax = plt.subplots(grid_size, grid_size, figsize=(15, 15))  # Adjust figure size\n",
    "    ax = ax.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i in range(len(image_list)):\n",
    "        img = imread(image_list[i])\n",
    "        name = image_list[i].split(\"/\")[-1].split(\".\")[0]\n",
    "        ax[i].imshow(img, cmap='gray')  # Show the image\n",
    "        ax[i].set_title(name, fontsize=12)  # Set the title for each image\n",
    "        ax[i].axis('off')  # Hide axes for a cleaner look\n",
    "\n",
    "    # Hide unused subplots (if any)\n",
    "    for i in range(len(image_list), len(ax)):\n",
    "        ax[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_input(image_list[:9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T06:30:55.851540Z",
     "iopub.status.busy": "2025-01-06T06:30:55.851171Z",
     "iopub.status.idle": "2025-01-06T06:30:55.861293Z",
     "shell.execute_reply": "2025-01-06T06:30:55.860403Z",
     "shell.execute_reply.started": "2025-01-06T06:30:55.851514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        # Register hooks\n",
    "        target_layer.register_forward_hook(self.save_activation)\n",
    "        target_layer.register_full_backward_hook(self.save_gradient)\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def __call__(self, x, class_idx=None):\n",
    "        # Forward pass\n",
    "        self.model.eval()\n",
    "        output = self.model(x)\n",
    "\n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1)\n",
    "\n",
    "        # Zero gradients\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        # Target for backprop\n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[0][class_idx] = 1\n",
    "\n",
    "        # Backward pass\n",
    "        output.backward(gradient=one_hot, retain_graph=True)\n",
    "\n",
    "        # Global average pooling of gradients\n",
    "        weights = torch.mean(self.gradients, dim=(2, 3))\n",
    "\n",
    "        # Weight the activations\n",
    "        cam = torch.zeros(self.activations.shape[2:], device=self.activations.device)\n",
    "        for i, w in enumerate(weights[0]):\n",
    "            cam += w * self.activations[0, i]\n",
    "\n",
    "        # Apply ReLU and normalize\n",
    "        cam = F.relu(cam)\n",
    "        cam = cam - torch.min(cam)\n",
    "        cam = cam / torch.max(cam)\n",
    "\n",
    "        return cam.detach()\n",
    "\n",
    "def visualize_cam(image, cam):\n",
    "    # Convert PIL Image to numpy array\n",
    "    if isinstance(image, Image.Image):\n",
    "        image_np = np.array(image)\n",
    "    else:\n",
    "        image_np = image\n",
    "\n",
    "    # Convert CAM to numpy array if it isn't already\n",
    "    if torch.is_tensor(cam):\n",
    "        cam = cam.cpu().numpy()\n",
    "\n",
    "    # Normalize CAM to 0-1 range if needed\n",
    "    if cam.max() > 1:\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "\n",
    "    # Ensure cam is the same size as the input image\n",
    "    cam_resized = cv2.resize(cam, (image_np.shape[1], image_np.shape[0]))\n",
    "\n",
    "    # Create heatmap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
    "\n",
    "    # Convert RGB to BGR if necessary (OpenCV uses BGR)\n",
    "    if len(image_np.shape) == 3 and image_np.shape[2] == 3:\n",
    "        image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Ensure both images have the same number of channels\n",
    "    if len(image_np.shape) != len(heatmap.shape):\n",
    "        if len(image_np.shape) == 2:\n",
    "            image_np = cv2.cvtColor(image_np, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Now combine them\n",
    "    result = cv2.addWeighted(image_np, 0.7, heatmap, 0.7, 5)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T06:55:13.581134Z",
     "iopub.status.busy": "2025-01-06T06:55:13.580775Z",
     "iopub.status.idle": "2025-01-06T06:55:16.691436Z",
     "shell.execute_reply": "2025-01-06T06:55:16.690450Z",
     "shell.execute_reply.started": "2025-01-06T06:55:13.581097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "num_samples = 6\n",
    "random_img_paths = random.sample(image_list, num_samples)\n",
    "\n",
    "for idx, path in enumerate(random_img_paths):\n",
    "    # Load and preprocess image\n",
    "    pil_image = Image.open(path).convert('RGB')\n",
    "\n",
    "\n",
    "    # Define transforms\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.Grayscale(num_output_channels=3),  \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),\n",
    "    ])\n",
    "\n",
    "    # Transform and add batch dimension\n",
    "\n",
    "    input_tensor = transform(pil_image).unsqueeze(0)\n",
    "\n",
    "    # Move everything to GPU if available\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = best_model.to(device)\n",
    "    target_layer = model.features[-1]\n",
    "    grad_cam = GradCAM(model, target_layer)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    # Generate CAM\n",
    "    cam = grad_cam(input_tensor)\n",
    "    # Visualize\n",
    "    input_image = transforms.ToPILImage()(input_tensor.squeeze(0).cpu())\n",
    "    result = visualize_cam(input_image, cam)\n",
    "\n",
    "     # Plot original and Grad-CAM\n",
    "    plt.subplot(num_samples, 2, 2*idx + 1)\n",
    "    plt.imshow(pil_image)\n",
    "    plt.title(f'Original -')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(num_samples, 2, 2*idx + 2)\n",
    "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Grad-CAM')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T06:56:40.478574Z",
     "iopub.status.busy": "2025-01-06T06:56:40.478250Z",
     "iopub.status.idle": "2025-01-06T06:56:42.048701Z",
     "shell.execute_reply": "2025-01-06T06:56:42.047667Z",
     "shell.execute_reply.started": "2025-01-06T06:56:40.478546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_predictions_from_loader(val_loader, model, class_names, transform=None):\n",
    "    \"\"\"\n",
    "    Predict and display the first 8 images from the validation loader with their predicted and actual labels.\n",
    "\n",
    "    Args:\n",
    "        val_loader (DataLoader): DataLoader for validation dataset.\n",
    "        model (torch.nn.Module): Trained PyTorch model for prediction.\n",
    "        class_names (list): List of class names corresponding to class indices.\n",
    "        transform (callable): Transformations to apply to the images before prediction.\n",
    "    \"\"\"\n",
    "    # Create a grid for visualization\n",
    "    fig, ax = plt.subplots(3, 4, figsize=(20, 10))  # 2 rows, 4 columns\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Get the first batch of data from the validation loader\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(val_loader):\n",
    "            if i == 0:  # Only take the first batch\n",
    "                break\n",
    "\n",
    "        # Make sure we only use the first 8 images\n",
    "        images = images[:12]\n",
    "        labels = labels[:12]\n",
    "\n",
    "        # Send the images and labels to the same device as the model\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Make predictions\n",
    "        outputs = model(images)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "\n",
    "        # Convert tensors to CPU and numpy for display\n",
    "        images = images.cpu()\n",
    "        predicted_labels = predicted_labels.cpu()\n",
    "        labels = labels.cpu()\n",
    "\n",
    "        # Display the images with actual and predicted labels\n",
    "        for i in range(12):\n",
    "            img = images[i].cpu().numpy().transpose((1, 2, 0))  # Convert to HWC format\n",
    "            ax[i].imshow(img)\n",
    "            ax[i].axis('off')  # Hide axes for a cleaner look\n",
    "            ax[i].set_title(\n",
    "                f\"Actual: {class_names[labels[i]]}\\nPredicted: {class_names[predicted_labels[i]]}\",\n",
    "                fontsize=12\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "class_names = ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "# Assuming `val_loader` is your validation data loader\n",
    "visualize_predictions_from_loader(val_loader, best_model, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T07:06:40.594939Z",
     "iopub.status.busy": "2025-01-06T07:06:40.594658Z",
     "iopub.status.idle": "2025-01-06T07:06:45.913192Z",
     "shell.execute_reply": "2025-01-06T07:06:45.912197Z",
     "shell.execute_reply.started": "2025-01-06T07:06:40.594917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "from torchsummary import summary\n",
    "\n",
    "def archit(model):\n",
    "    summary(model, (3, 224, 224))\n",
    "    dummy_input = torch.randn(16, 3, 224, 224).to(device) \n",
    "    \n",
    "    output = net(dummy_input).to(device)\n",
    "    \n",
    "    dot = make_dot(output, params=dict(net.named_parameters()))\n",
    "    \n",
    "    dot.render(\"model_architecture1\", format=\"png\") \n",
    "    dot.view()\n",
    "\n",
    "archit(best_model)\n",
    "archit(custom_best_model)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dipenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
